neural
network
model
have
show
their
promising
opportunity
for
multi-task
learning
,
which
focus
on
learn
the
share
layer
to
extract
the
common
and
task-invariant
feature
.
however
,
in
much
existing
approach
,
the
extract
share
feature
be
prone
to
be
contaminate
by
task-specific
feature
or
the
noise
bring
by
other
task
.
in
this
paper
,
we
propose
a
adversarial
multi-task
learn
framework
,
alleviate
the
share
and
private
latent
feature
space
from
interfere
with
each
other
.
we
conduct
extensive
experiment
on
16
different
text
classification
task
,
which
demonstrate
the
benefit
of
our
approach
.
besides
,
we
show
that
the
share
knowledge
learn
by
our
proposed
model
can
be
regard
as
off-the-shelf
knowledge
and
easily
transfer
to
new
task
.
multi-task
learning
be
a
effective
approach
to
improve
the
performance
of
a
single
task
with
the
help
of
other
related
task
.
recently
,
neural-based
model
for
multi-task
learning
have
become
very
popular
,
range
from
computer
vision
-LRB-
Misra
et
al.
,
2016
;
Zhang
et
al.
,
2014
-RRB-
to
natural
language
processing
-LRB-
Collobert
andweston
,
2008
;
Luong
et
al.
,
2015
-RRB-
,
since
they
provide
a
convenient
way
of
combine
information
from
multiple
task
.
however
,
much
exist
work
on
multi-task
learning
-LRB-
Liu
et
al.
,
2016c
,
b
-RRB-
attempt
to
divide
the
feature
of
different
task
into
private
and
share
space
,
merely
base
on
whether
parameter
of
some
component
should
be
share
.
as
show
in
figure
1
-
-LRB-
a
-RRB-
,
the
general
shared-private
model
introduce
two
feature
space
for
any
task
:
one
be
use
to
store
task-dependent
feature
,
the
other
be
use
to
capture
share
feature
.
the
major
limitation
of
this
framework
be
that
the
share
feature
space
can
contain
some
unnecessary
task-specific
feature
,
while
some
sharable
feature
can
also
be
mixed
in
private
space
,
suffer
from
feature
redundancy
.
take
the
follow
two
sentence
as
example
,
which
be
extract
from
two
different
sentiment
classification
task
:
Movie
review
and
Baby
product
review
.
the
infantile
cart
be
simple
and
easy
to
use
.
this
kind
of
humour
be
infantile
and
boring
.
the
word
infantile
indicate
negative
sentiment
in
Movie
task
while
it
be
neutral
in
Baby
task
.
however
,
the
general
shared-private
model
can
place
the
task-specific
word
infantile
in
a
share
space
,
leave
potential
hazard
for
other
task
.
additionally
,
the
capacity
of
share
space
can
also
be
waste
by
some
unnecessary
feature
.
to
address
this
problem
,
in
this
paper
we
propose
a
adversarial
multi-task
framework
,
in
which
the
share
and
private
feature
space
be
in
herently
disjoint
by
introduce
orthogonality
constraints.specifically
,
we
design
a
generic
share
private
learning
framework
to
model
the
text
sequence
.
