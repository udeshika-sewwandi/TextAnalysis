Neural network models have shown their promising opportunities for multi-task learning , which focus on learning the shared layers to extract the common and task-invariant features .  : {"_type": "SpellCheck", "flaggedTokens": [{"offset": 78, "token": "learning , which", "type": "UnknownToken", "suggestions": [{"suggestion": "learning, which", "score": 0.875}]}]}

However , in most existing approaches , the extracted shared features are prone to be contaminated by task-specific features or the noise brought by other tasks .  : {"_type": "SpellCheck", "flaggedTokens": [{"offset": 0, "token": "However , in", "type": "UnknownToken", "suggestions": [{"suggestion": "However, in", "score": 0.875}]}, {"offset": 27, "token": "approaches , the", "type": "UnknownToken", "suggestions": [{"suggestion": "approaches, the", "score": 0.875}]}]}

In this paper , we propose an adversarial multi-task learning framework , alleviating the shared and private latent feature spaces from interfering with each other .  : {"_type": "SpellCheck", "flaggedTokens": [{"offset": 8, "token": "paper , we", "type": "UnknownToken", "suggestions": [{"suggestion": "paper, we", "score": 0.875}]}, {"offset": 62, "token": "framework , alleviating", "type": "UnknownToken", "suggestions": [{"suggestion": "framework, alleviating", "score": 0.875}]}]}

We conduct extensive experiments on 16 different text classification tasks , which demonstrates the benefits of our approach .  : {"_type": "SpellCheck", "flaggedTokens": [{"offset": 69, "token": "tasks , which", "type": "UnknownToken", "suggestions": [{"suggestion": "tasks, which", "score": 0.875}]}]}

Besides , we show that the shared knowledge learned by our proposed model can be regarded as off-the-shelf knowledge and easily transferred to new tasks .  : {"_type": "SpellCheck", "flaggedTokens": [{"offset": 0, "token": "Besides , we", "type": "UnknownToken", "suggestions": [{"suggestion": "Besides, we", "score": 0.875}]}]}

Multi-task learning is an effective approach to improve the performance of a single task with the help of other related tasks .  : {"_type": "SpellCheck", "flaggedTokens": []}

Recently , neural-based models for multi-task learning have become very popular , ranging from computer vision -LRB- Misra et al. , 2016 ; Zhang et al. , 2014 -RRB- to natural language processing -LRB- Collobert andWeston , 2008 ; Luong et al. , 2015 -RRB- , since they provide a convenient way of combining information from multiple tasks .  : {"_type": "SpellCheck", "flaggedTokens": [{"offset": 0, "token": "Recently , neural", "type": "UnknownToken", "suggestions": [{"suggestion": "Recently, neural", "score": 0.875}]}, {"offset": 72, "token": "popular , ranging", "type": "UnknownToken", "suggestions": [{"suggestion": "popular, ranging", "score": 0.875}]}, {"offset": 132, "token": "2016 ; Zhang", "type": "UnknownToken", "suggestions": [{"suggestion": "2016; Zhang", "score": 0.875}]}, {"offset": 212, "token": "andWeston", "type": "UnknownToken", "suggestions": [{"suggestion": "and Weston", "score": 0.6996663564954817}]}, {"offset": 224, "token": "2008 ; Luong", "type": "UnknownToken", "suggestions": [{"suggestion": "2008; Luong", "score": 0.875}]}]}

However , most existing work on multi-task learning -LRB- Liu et al. , 2016c , b -RRB- attempts to divide the features of different tasks into private and shared spaces , merely based on whether parameters of some components should be shared .  : {"_type": "SpellCheck", "flaggedTokens": [{"offset": 0, "token": "However , most", "type": "UnknownToken", "suggestions": [{"suggestion": "However, most", "score": 0.875}]}, {"offset": 71, "token": "2016c , b", "type": "UnknownToken", "suggestions": [{"suggestion": "2016c, b", "score": 0.875}]}, {"offset": 162, "token": "spaces , merely", "type": "UnknownToken", "suggestions": [{"suggestion": "spaces, merely", "score": 0.875}]}]}

As shown in Figure 1 - -LRB- a -RRB- , the general shared-private model introduces two feature spaces for any task : one is used to store task-dependent features , the other is used to capture shared features .  : {"_type": "SpellCheck", "flaggedTokens": [{"offset": 110, "token": "task : one", "type": "UnknownToken", "suggestions": [{"suggestion": "task: one", "score": 0.875}]}, {"offset": 153, "token": "features , the", "type": "UnknownToken", "suggestions": [{"suggestion": "features, the", "score": 0.875}]}]}

The major limitation of this framework is that the shared feature space could contain some unnecessary task-specific features , while some sharable features could also be mixed in private space , suffering from feature redundancy .  : {"_type": "SpellCheck", "flaggedTokens": [{"offset": 117, "token": "features , while", "type": "UnknownToken", "suggestions": [{"suggestion": "features, while", "score": 0.875}]}, {"offset": 188, "token": "space , suffering", "type": "UnknownToken", "suggestions": [{"suggestion": "space, suffering", "score": 0.875}]}]}

Taking the following two sentences as examples , which are extracted from two different sentiment classification tasks : Movie reviews and Baby products reviews .  : {"_type": "SpellCheck", "flaggedTokens": [{"offset": 38, "token": "examples , which", "type": "UnknownToken", "suggestions": [{"suggestion": "examples, which", "score": 0.875}]}, {"offset": 113, "token": "tasks : Movie", "type": "UnknownToken", "suggestions": [{"suggestion": "tasks: Movie", "score": 0.875}]}]}

The infantile cart is simple and easy to use .  : {"_type": "SpellCheck", "flaggedTokens": []}

This kind of humour is infantile and boring .  : {"_type": "SpellCheck", "flaggedTokens": [{"offset": 13, "token": "humour", "type": "UnknownToken", "suggestions": [{"suggestion": "humor", "score": 0.875}]}]}

The word infantile indicates negative sentiment in Movie task while it is neutral in Baby task .  : {"_type": "SpellCheck", "flaggedTokens": []}

However , the general shared-private model could place the task-specific word infantile in a shared space , leaving potential hazards for other tasks .  : {"_type": "SpellCheck", "flaggedTokens": [{"offset": 0, "token": "However , the", "type": "UnknownToken", "suggestions": [{"suggestion": "However, the", "score": 0.875}]}, {"offset": 100, "token": "space , leaving", "type": "UnknownToken", "suggestions": [{"suggestion": "space, leaving", "score": 0.875}]}]}

Additionally , the capacity of shared space could also be wasted by some unnecessary features .  : {"_type": "SpellCheck", "flaggedTokens": [{"offset": 0, "token": "Additionally , the", "type": "UnknownToken", "suggestions": [{"suggestion": "Additionally, the", "score": 0.875}]}]}

To address this problem , in this paper we propose an adversarial multi-task framework , in which the shared and private feature spaces are in herently disjoint by introducing orthogonality constraints.Specifically , we design a generic shared private learning framework to model the text sequence .  : {"_type": "SpellCheck", "flaggedTokens": [{"offset": 16, "token": "problem , in", "type": "UnknownToken", "suggestions": [{"suggestion": "problem, in", "score": 0.875}]}, {"offset": 77, "token": "framework , in", "type": "UnknownToken", "suggestions": [{"suggestion": "framework, in", "score": 0.875}]}, {"offset": 140, "token": "in herently", "type": "UnknownToken", "suggestions": [{"suggestion": "inherently", "score": 0.8723696906745475}]}, {"offset": 202, "token": "Specifically , we", "type": "UnknownToken", "suggestions": [{"suggestion": "Specifically, we", "score": 0.875}]}]}

